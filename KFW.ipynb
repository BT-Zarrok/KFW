{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladesäulen\n",
    "\n",
    "Von  Jannis Breitenstein <br>\n",
    "\n",
    "\n",
    "Diese Notebook ist in folgende Abschnitte unterteilt:\n",
    "\n",
    "+ [1. Import Bibliotheken](#1)<br>\n",
    "+ [2. Laden und Aufbereiten der Zapfsäulendaten](#2)<br>\n",
    "+ [2.1 Laden und Aufbereitung der Daten](#2.1)<br>\n",
    "+ [2.2 Exportieren und Einlesen der Daten](#2.1)<br>\n",
    "+ [3. Explorative Datenanalyse](#3)<br>\n",
    "+ [3.1 Allgeime Daten über die Datensets](#3.1)<br>\n",
    "+ [3.2 Veröffentlichung der Filme](#3.2)<br>\n",
    "+ [3.3 Verteilung der Filmbewertungen](#3.3)<br>\n",
    "+ [3.4 Wann sind die Filme bewertet worden](#3.4)<br>\n",
    "+ [3.5 Verteilung von Filmbewertungen und Benutzern](#3.5)<br>\n",
    "+ [4. Filtern der Daten](#4)<br>\n",
    "+ [5. Anweden des KNN-Modells](#5)<br>\n",
    "+ [5.1 Vorbereitung des KNN-Modells](#5.1)<br>\n",
    "+ [5.2 Berechnung von allen Nachbarn und Export](#5.2)<br>\n",
    "+ [5.3 Vorbereitung für Precision and Recall](#5.3)<br>\n",
    "+ [5.4 Presicion and Recall](#5.4)<br>\n",
    "+ [5.5 Empfehlung mit Hilfe des Fuzzy Algorithmus](#5.5)<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  cd C:\\Python\\KFW_V1\n",
    "##  !{sys.executable} -m pipenv shell\n",
    "## dsad\n",
    "\"\"\"\n",
    "pip3 install virtualenv\n",
    "cd C:\\Python\\KFW_V1\\kfw> \n",
    "python -m venv kfw  --> Zum Erstellen, wenn bereits vorhanden dann Active\n",
    ".\\kfw\\Scripts\\activate\n",
    "--> When Activation is failing: Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy Unrestricted --> Repeat step four\n",
    "--> to run the Jupyter Notebook in virtual Enviroment it is recommended to install all jupyter dependencies --> !{sys.executable} -m pip3 install jupyter\n",
    "\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=1>1. Import Bibliotheken </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "!{sys.executable} --version\n",
    "print(sys.executable)\n",
    "!{sys.executable} -m pip install autokeras\n",
    "!{sys.executable} -m pip install altair\n",
    "!{sys.executable} -m pip install bayesian-optimization\n",
    "!{sys.executable} -m pip install chart_studio\n",
    "!{sys.executable} -m pip install cx_Oracle\n",
    "!{sys.executable} -m pip install dython\n",
    "!{sys.executable} -m pip install fastparquet\n",
    "!{sys.executable} -m pip install fuzzywuzzy\n",
    "!{sys.executable} -m pip install geopandas\n",
    "!{sys.executable} -m pip install graphviz\n",
    "!{sys.executable} -m pip install glom\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "!{sys.executable} -m pip install ipython-sql\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install lime\n",
    "!{sys.executable} -m pip install nltk\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install numpy\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install notebook \n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install pandas\n",
    "#\n",
    "!{sys.executable} -m pip install pillow\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "!{sys.executable} -m pip install python-Levenshtein\n",
    "!{sys.executable} -m pip install prettytable\n",
    "!{sys.executable} -m pip install pyspark\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install scipy\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install surprise\n",
    "!{sys.executable} -m pip install scikit-surprise \n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install spaCy\n",
    "!{sys.executable} -m pip install sqlalchemy\n",
    "!{sys.executable} -m pip install talos\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install wrangle\n",
    "!{sys.executable} -m pip install requests\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zum Speichern der Daten\n",
    "import pandas as pd\n",
    "\n",
    "# Wird zur Erstellung mehrdimensionalen Arrays benötigt\n",
    "import numpy as np\n",
    "\n",
    "# interaktive Diagramme erstellen\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id=2>2. Laden und Aufbereiten der Daten </a>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Datenaufbereitung </a>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define actual Datapath\n",
    "path = \"C:/Python/KFW_V1/Ladesaeulenregister.csv\"\n",
    "\n",
    "df_raw= pd.read_csv(path,\n",
    "                encoding = \"ISO-8859-1\",\n",
    "                delimiter= ';',\n",
    "                decimal= ',',\n",
    "                skiprows = 10,\n",
    "                engine = 'python')\n",
    "\n",
    "\n",
    "del  path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw\n",
    "\n",
    "## Daten in Float Formatieren\n",
    "\n",
    "df = df[df['Breitengrad'].str.contains('52,19168124567324.') == False]\n",
    "df['Breitengrad'] = df['Breitengrad'].astype(float)\n",
    "\n",
    "#df['Breitengrad'] = df['Breitengrad'].replace('.',',')\n",
    "\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace(',','.') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace(',','.') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace('','') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace(' ','') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace('','0')\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].astype(float)\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace('.',',')\n",
    "\n",
    "df['Inbetriebnahmedatum'] = pd.to_datetime(df.Inbetriebnahmedatum, dayfirst= True)\n",
    "\n",
    "Convert_df= {'Betreiber': 'object',\n",
    "                 'Straße': 'object', \n",
    "                 'Hausnummer': 'object',\n",
    "                 'Adresszusatz' : 'object',\n",
    "                 'Ort' : 'object',\n",
    "                 'Bundesland' : 'object',\n",
    "                 'Kreis/kreisfreie Stadt' : 'object',\n",
    "                 'Breitengrad' : 'float',\n",
    "                 'Längengrad' : 'float',\n",
    "                 'Inbetriebnahmedatum' : 'datetime64',\n",
    "                 'Anschlussleistung' : 'float',\n",
    "                 'Normalladeeinrichtung' : 'object',\n",
    "                 'Anzahl Ladepunkte' : 'int64',\n",
    "                 'Steckertypen1' : 'object',\n",
    "                 'P1 [kW]' : 'float',\n",
    "                 'Public Key1' : 'object',\n",
    "                 'Steckertypen2' : 'object',\n",
    "                 'P2 [kW]' : 'float',\n",
    "                 'Public Key2' : 'object',\n",
    "                 'Steckertypen3' : 'object',\n",
    "                 'P3 [kW]' : 'float',\n",
    "                 'Public Key3' : 'object',\n",
    "                 'Steckertypen4' : 'object',\n",
    "                 'P4 [kW]' : 'float',\n",
    "                 'Public Key4' : 'object'\n",
    "                  }\n",
    "\n",
    "df = df.astype(Convert_df)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2.2 Allgemeine Informationen zum Datenset </a>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_raw\n",
    "# Ausgabe Datentypen\n",
    "#What are the datatypes in each column?\n",
    "print(df.info())\n",
    "\n",
    "# Let's see what attributes columns we have.\n",
    "print(df.columns)\n",
    "\n",
    "# There are quite some columns. How many, actually?\n",
    "# How many columns do you have?\n",
    "print(len(df.columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wie viele Datensätze haben wir sprich Spalten\n",
    "print(len(df.index))\n",
    "\n",
    "# Was ist die Dimension vom Datenset\n",
    "#What is the dimension of the dataset? Note: Your answer should be a tuple value.\n",
    "print(df.shape)\n",
    "\n",
    "## Wie viele Werte haben die einzelen Spalten\n",
    "print(df.count())\n",
    "\n",
    "## Anzeigen der aktuellen Datenstruktur\n",
    "#display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Löschen von doppelten Spalten\n",
    "df_f = df\n",
    "\n",
    "# Drop all rows with NaN.\n",
    "df_f = df_f.dropna(axis = 0, how = 'all', inplace = False)\n",
    "#df_f = df_f.fillna(\"\", inplace=False)\n",
    "\n",
    "#df_null_values = df_f.isnull().sum()\n",
    "\n",
    "\n",
    "print('Vor dem entfernen hatte der Datensatz {} Zeilen. Nach dem entfernen {}  Insgesamt wurden  entfernt'.format(len(df.index), len(df_f.index) ))\n",
    "\n",
    "del df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Ausgabe der Duplikate\n",
    "dupli = df.duplicated(keep=False).sum()\n",
    "print('In dem Datensatz Ladensauelenregister liegen {} Duplikate vor'.format(dupli))\n",
    "\n",
    "duplicateRowsDF = df[df.duplicated()]\n",
    "duplicateRowsDF = duplicateRowsDF.sort_values(by=['Breitengrad'])\n",
    "display(duplicateRowsDF)\n",
    "\n",
    "\n",
    "del duplicateRowsDF , dupli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exportieren der Dateien in eine CSV\n",
    "\n",
    "path_csv = \"C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.csv\"\n",
    "df.to_csv(path_csv,\n",
    "            sep = ';',\n",
    "            header = True,\n",
    "            index= True,\n",
    "            decimal= ','\n",
    "            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportieren der Daten in ein Parquet\n",
    "parquet_df= 'C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.zip'\n",
    "df.to_parquet(parquet_df, index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "# <a id=2>2. Explorative Datenanalyse </a>\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Importieren der Daten </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_df= 'C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.zip'\n",
    "df = pd.read_parquet(parquet_df)\n",
    "\n",
    "Convert_df= {'Betreiber': 'object', \n",
    "                 'Straße': 'object', \n",
    "                 'Hausnummer': 'object',\n",
    "                 'Adresszusatz' : 'object',\n",
    "                 'Ort' : 'object',\n",
    "                 'Bundesland' : 'object',\n",
    "                 'Kreis/kreisfreie Stadt' : 'object',\n",
    "                 'Breitengrad' : 'float',\n",
    "                 'Längengrad' : 'float',\n",
    "                 'Inbetriebnahmedatum' : 'datetime64',\n",
    "                 'Anschlussleistung' : 'float',\n",
    "                 'Normalladeeinrichtung' : 'object',\n",
    "                 'Anzahl Ladepunkte' : 'int64',\n",
    "                 'Steckertypen1' : 'object',\n",
    "                 'P1 [kW]' : 'float',\n",
    "                 'Public Key1' : 'object',\n",
    "                 'Steckertypen2' : 'object',\n",
    "                 'P2 [kW]' : 'float',\n",
    "                 'Public Key2' : 'object',\n",
    "                 'Steckertypen3' : 'object',\n",
    "                 'P3 [kW]' : 'float',\n",
    "                 'Public Key3' : 'object',\n",
    "                 'Steckertypen4' : 'object',\n",
    "                 'P4 [kW]' : 'float',\n",
    "                 'Public Key4' : 'object'\n",
    "                  }\n",
    "\n",
    "df = df.astype(Convert_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Allgeime Daten über die Datensets </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show missing values in a figure --> Get first Idea how Much Data is missing\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='Greys')\n",
    "plt.xticks(rotation=45, fontsize=6)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('C:/Python/KFW_V1/Ladesaeulenregister_Duplis.pdf')\n",
    "plt.plot()\n",
    "#plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl der Betreiber bei Gruppe \\n ')\n",
    "df_Betreiber_cnt_tmp = df.groupby(['Betreiber'])['Betreiber'].count().sort_values(ascending=False)\n",
    "print(df_Betreiber_cnt_tmp.head(10))\n",
    "print('\\n')\n",
    "\n",
    "print( '# Anzahl der Normalladeeinrichtung \\n')\n",
    "df_n_cnt = df.groupby(['Normalladeeinrichtung'])['Normalladeeinrichtung'].count().sort_values(ascending=False)\n",
    "print(df_n_cnt.head(10))\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Gruppierung nach Anschlussleistung \\n') \n",
    "df_An_cnt = df.groupby(['Anschlussleistung'])['Anschlussleistung'].count().sort_values(ascending=False)\n",
    "print(df_An_cnt.head(10))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Gruppierung nach Bundesland \\n') \n",
    "df_B_cnt = df.groupby(['Bundesland'])['Bundesland'].count().sort_values(ascending=False)\n",
    "print(df_B_cnt.head(10))\n",
    "print('\\n')\n",
    "\n",
    "print('# Gruppierung nach Max Leistung \\n') \n",
    "df_kw_cnt = df.groupby(['P1 [kW]'])['P1 [kW]'].count().sort_values(ascending=False)\n",
    "print(df_kw_cnt.head(10))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl der maximalen Ladepunkten innerhalb von Deutschland \\n') \n",
    "df_lpm_cnt = df['Anzahl Ladepunkte']\n",
    "df_lpm_cnt = df_lpm_cnt.max()\n",
    "print(df_lpm_cnt)\n",
    "print('\\n')\n",
    "\n",
    "# Durchschnittswert\n",
    "print('# Ermittlung der Durchschnittswerte \\n') \n",
    "list_columns = ['Anschlussleistung',\n",
    "                'Anzahl Ladepunkte', 'P1 [kW]', 'P2 [kW]', 'P3 [kW]', 'P4 [kW]']\n",
    "df1 = df[list_columns]\n",
    "print(df1.mean(axis=0, skipna = True))\n",
    "\n",
    "\n",
    "\n",
    "# del df_Betreiber_cnt_tmp ,df_n_cnt ,df_An_cnt ,df_B_cnt ,df_kw_cnt , df_lp_cnt, df_lpm_cnt , df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl von Ladepunkten innerhalb von Deutschland \\n') \n",
    "df_lp_cnt = df['Anzahl Ladepunkte']\n",
    "df_lp_cnt = df_lp_cnt.sum(axis = 0, skipna = True)\n",
    "print(df_lp_cnt)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten einholen\n",
    "#data = df['Inbetriebnahmedatum'].value_counts().sort_index()\n",
    "data = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y').value_counts().sort_index()\n",
    "#df['Inbetriebnahmedatum'] = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y')\n",
    "\n",
    "# Linie erstellen\n",
    "trace = go.Scatter(x = data.index,\n",
    "                   y = data.values,\n",
    "                   marker = dict(color = '#db0000'))\n",
    "# Layout erstellen\n",
    "layout = dict(title = '{} Ladesäulen sortiert nach Inbetriebnahme'.format(df.shape[0]),\n",
    "              xaxis = dict(title = 'Inbetriebnahmejahr'),\n",
    "              yaxis = dict(title = 'Säule'))\n",
    "\n",
    "# Plot erstellen\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)\n",
    "\n",
    "\n",
    "del layout, trace, fig, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellen der Stationen innerhalb Deutschland\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.Längengrad, df.Breitengrad))\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "cities = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n",
    "\n",
    "# We restrict to South America.\n",
    "ax = world[world.name == 'Germany'].plot(\n",
    "    color='white', edgecolor='black')\n",
    "\n",
    "\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "gdf.plot(ax=ax, color='blue',alpha = 0.1 , markersize=3 )\n",
    "\n",
    "## Mathplotly better\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Delete Ladesäulen which are out of Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = ['Anschlussleistung',\n",
    "                'Anzahl Ladepunkte', 'P1 [kW]', 'P2 [kW]', 'P3 [kW]', 'P4 [kW]']\n",
    "df = df[list_columns]\n",
    "corr_matrix = df.corr(method = 'pearson')\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Todos\n",
    "Data Analyses\n",
    "-   Correlation of \"Betreiber\" and \"KW 1\"\n",
    "    -   ONE Hot Encoding\n",
    "-  Some Zooming, missing City and Area \n",
    "\n",
    "\n",
    "\n",
    "Further Ideas\n",
    "- Prediction of future \"Anzahl Ladesäule\"\n",
    "    - Linear Regression\n",
    "    \n",
    "- Establish local data connection to e-car registrations and charging stations, to find out capacity gaps in some regions or not.\n",
    "    -  Which Cities are underpresented\n",
    "- Relate the coordinates of service areas and charging stations to find out if there are gaps.\n",
    "    - Missing Data of Coordinates\n",
    "    - \n",
    "- Distribution of fast charging stations in Germany. Maybe as preliminary work to connect the main traffic routes with it, afterwards.\n",
    "    -  Missing Data \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Inbetriebnahmedatum'] = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y')# Drop all rows with NaN.\n",
    "# df = df.dropna(axis=0)\n",
    "df_null_values = df.isnull().sum()\n",
    "# print('NANs_After_Update?', df_null_values)\n",
    "# print('// complete ........ Pre-Processing')\n",
    "# ------------------------------------------\n",
    "# Exploring the Data\n",
    "# ------------------------------------------\n",
    "# Select only the inserting one\n",
    "list_columns = ['Bundesland','Postleitzahl', 'Breitengrad', 'Längengrad',\n",
    "                'Inbetriebnahmedatum', 'Anschlussleistung',\n",
    "                'Normalladeeinrichtung', 'Anzahl Ladepunkte']\n",
    "df = df[list_columns]\n",
    "# Count column over yeas. Output: Series. Therefore, convert to pandas DataFrame.\n",
    "\n",
    "df_year_count = df['Inbetriebnahmedatum'].dt.year.value_counts().to_frame()\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "sns.barplot(data=df_year_count, x=df_year_count.index, y=\"Inbetriebnahmedatum\", color='gray',\n",
    "             linewidth=1.0)  # , marker='o', label='Portfolio Value', ax=ax[0])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=80)\n",
    "# plt.savefig('fig_count_plot_count_year.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('// complete ....... count plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Training data\n",
    "years = [1900, 1950, 2000, 2010, 2020]\n",
    "populations = [1.65, 2.55, 6.14, 6.89, 7.79]\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression().fit(np.array(years).reshape(-1, 1), np.array(populations))\n",
    "\n",
    "# Make predictions for the next 10 years\n",
    "years_future = [2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100]\n",
    "populations_pred = model.predict(np.array(years_future).reshape(-1, 1))\n",
    "\n",
    "# Print the predicted populations\n",
    "for year, population in zip(years_future, populations_pred):\n",
    "    print(f'Predicted population in {year}: {population} billion')\n",
    "\n",
    "print(populations_pred.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.84636364  8.37272727  8.89909091  9.42545455  9.95181818 10.47818182\n",
      " 11.00454545 11.53090909]\n"
     ]
    }
   ],
   "source": [
    "print(populations_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('KFW_V1-n7B7ZO_c')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a6d2462e65ed54794c76e3a764d49c7eaa874fbe4b0612b96e60aa5b8bc5bc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
