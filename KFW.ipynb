{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladesäulen KFW rc\n",
    "\n",
    "Von  Jannis Breitenstein <br>\n",
    "\n",
    "\n",
    "Diese Notebook ist in folgende Abschnitte unterteilt:\n",
    "z67u.[]\n",
    "+ [1. Import Bibliotheken](#1)<br>\n",
    "+ [2. Laden und Aufbereiten der Zapfsäulendaten](#2)<br>\n",
    "+ [2.1 Laden und Aufbereitung der Daten](#2.1)<br>\n",
    "+ [2.2 Exportieren und Einlesen der Daten](#2.1)<br>\n",
    "+ [3. Explorative Datenanalyse](#3)<br>\n",
    "+ [3.1 Allgeime Daten über die Datensets](#3.1)<br>\n",
    "+ [3.2 Veröffentlichung der Filme](#3.2)<br>\n",
    "+ [3.3 Verteilung der Filmbewertungen](#3.3)<br>\n",
    "+ [3.4 Wann sind die Filme bewertet worden](#3.4)<br>\n",
    "+ [3.5 Verteilung von Filmbewertungen und Benutzern](#3.5)<br>\n",
    "+ [4. Filtern der Daten](#4)<br>\n",
    "+ [5. Anweden des KNN-Modells](#5)<br>\n",
    "+ [5.1 Vorbereitung des KNN-Modells](#5.1)<br>\n",
    "+ [5.2 Berechnung von allen Nachbarn und Export](#5.2)<br>\n",
    "+ [5.3 Vorbereitung für Precision and Recall](#5.3)<br>\n",
    "+ [5.4 Presicion and Recall](#5.4)<br>\n",
    "+ [5.5 Empfehlung mit Hilfe des Fuzzy Algorithmus](#5.5)<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  cd C:\\Python\\KFW_V1\n",
    "##  !{sys.executable} -m pipenv shell\n",
    "## dsad\n",
    "\"\"\"\n",
    "pip3 install virtualenv\n",
    "cd C:\\Python\\KFW_V1\\kfw> \n",
    "python -m venv kfw  --> Zum Erstellen, wenn bereits vorhanden dann Active\n",
    ".\\kfw\\Scripts\\activate\n",
    "--> When Activation is failing: Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy Unrestricted --> Repeat step four\n",
    "--> to run the Jupyter Notebook in virtual Enviroment it is recommended to install all jupyter dependencies --> !{sys.executable} -m pip3 install jupyter\n",
    "\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=1>1. Import Bibliotheken </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "!{sys.executable} --version\n",
    "print(sys.executable)\n",
    "!{sys.executable} -m pip install autokeras\n",
    "!{sys.executable} -m pip install altair\n",
    "!{sys.executable} -m pip install bayesian-optimization\n",
    "!{sys.executable} -m pip install chart_studio\n",
    "!{sys.executable} -m pip install cx_Oracle\n",
    "!{sys.executable} -m pip install dython\n",
    "!{sys.executable} -m pip install fastparquet\n",
    "!{sys.executable} -m pip install fuzzywuzzy\n",
    "!{sys.executable} -m pip install geopandas\n",
    "!{sys.executable} -m pip install graphviz\n",
    "!{sys.executable} -m pip install glom\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "!{sys.executable} -m pip install ipython-sql\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install lime\n",
    "!{sys.executable} -m pip install nltk\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install numpy\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install notebook \n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install pandas\n",
    "#\n",
    "!{sys.executable} -m pip install pillow\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "!{sys.executable} -m pip install python-Levenshtein\n",
    "!{sys.executable} -m pip install prettytable\n",
    "!{sys.executable} -m pip install pyspark\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install scipy\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install surprise\n",
    "!{sys.executable} -m pip install scikit-surprise \n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install spaCy\n",
    "!{sys.executable} -m pip install sqlalchemy\n",
    "!{sys.executable} -m pip install talos\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install wrangle\n",
    "!{sys.executable} -m pip install requests\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zum Speichern der Daten\n",
    "import pandas as pd\n",
    "\n",
    "# Wird zur Erstellung mehrdimensionalen Arrays benötigt\n",
    "import numpy as np\n",
    "\n",
    "# interaktive Diagramme erstellen\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Lineare Regression \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Datetime\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id=2>2. Laden und Aufbereiten der Daten </a>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Datenaufbereitung </a>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define actual Datapath\n",
    "path = \"C:/Python/KFW_V1/Ladesaeulenregister.csv\"\n",
    "\n",
    "df_raw= pd.read_csv(path,\n",
    "                encoding = \"ISO-8859-1\",\n",
    "                delimiter= ';',\n",
    "                decimal= ',',\n",
    "                skiprows = 10,\n",
    "                engine = 'python')\n",
    "\n",
    "\n",
    "del  path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw\n",
    "\n",
    "## Daten in Float Formatieren\n",
    "\n",
    "df = df[df['Breitengrad'].str.contains('52,19168124567324.') == False]\n",
    "df['Breitengrad'] = df['Breitengrad'].astype(float)\n",
    "\n",
    "#df['Breitengrad'] = df['Breitengrad'].replace('.',',')\n",
    "\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace(',','.') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace(',','.') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace('','') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace(' ','') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace('','0')\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].astype(float)\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace('.',',')\n",
    "\n",
    "df['Inbetriebnahmedatum'] = pd.to_datetime(df.Inbetriebnahmedatum, dayfirst= True)\n",
    "\n",
    "Convert_df= {'Betreiber': 'object',\n",
    "                 'Straße': 'object', \n",
    "                 'Hausnummer': 'object',\n",
    "                 'Adresszusatz' : 'object',\n",
    "                 'Ort' : 'object',\n",
    "                 'Bundesland' : 'object',\n",
    "                 'Kreis/kreisfreie Stadt' : 'object',\n",
    "                 'Breitengrad' : 'float',\n",
    "                 'Längengrad' : 'float',\n",
    "                 'Inbetriebnahmedatum' : 'datetime64',\n",
    "                 'Anschlussleistung' : 'float',\n",
    "                 'Normalladeeinrichtung' : 'object',\n",
    "                 'Anzahl Ladepunkte' : 'int64',\n",
    "                 'Steckertypen1' : 'object',\n",
    "                 'P1 [kW]' : 'float',\n",
    "                 'Public Key1' : 'object',\n",
    "                 'Steckertypen2' : 'object',\n",
    "                 'P2 [kW]' : 'float',\n",
    "                 'Public Key2' : 'object',\n",
    "                 'Steckertypen3' : 'object',\n",
    "                 'P3 [kW]' : 'float',\n",
    "                 'Public Key3' : 'object',\n",
    "                 'Steckertypen4' : 'object',\n",
    "                 'P4 [kW]' : 'float',\n",
    "                 'Public Key4' : 'object'\n",
    "                  }\n",
    "\n",
    "df = df.astype(Convert_df)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2.2 Allgemeine Informationen zum Datenset </a>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_raw\n",
    "# Ausgabe Datentypen\n",
    "#What are the datatypes in each column?\n",
    "print(df.info())\n",
    "\n",
    "# Let's see what attributes columns we have.\n",
    "print(df.columns)\n",
    "\n",
    "# There are quite some columns. How many, actually?\n",
    "# How many columns do you have?\n",
    "print(len(df.columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wie viele Datensätze haben wir sprich Spalten\n",
    "print(len(df.index))\n",
    "\n",
    "# Was ist die Dimension vom Datenset\n",
    "#What is the dimension of the dataset? Note: Your answer should be a tuple value.\n",
    "print(df.shape)\n",
    "\n",
    "## Wie viele Werte haben die einzelen Spalten\n",
    "print(df.count())\n",
    "\n",
    "## Anzeigen der aktuellen Datenstruktur\n",
    "#display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Löschen von doppelten Spalten\n",
    "df_f = df\n",
    "\n",
    "# Drop all rows with NaN.\n",
    "df_f = df_f.dropna(axis = 0, how = 'all', inplace = False)\n",
    "#df_f = df_f.fillna(\"\", inplace=False)\n",
    "\n",
    "#df_null_values = df_f.isnull().sum()\n",
    "\n",
    "\n",
    "print('Vor dem entfernen hatte der Datensatz {} Zeilen. Nach dem entfernen {}  Insgesamt wurden  entfernt'.format(len(df.index), len(df_f.index) ))\n",
    "\n",
    "del df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Ausgabe der Duplikate\n",
    "dupli = df.duplicated(keep=False).sum()\n",
    "print('In dem Datensatz Ladensauelenregister liegen {} Duplikate vor'.format(dupli))\n",
    "\n",
    "duplicateRowsDF = df[df.duplicated()]\n",
    "duplicateRowsDF = duplicateRowsDF.sort_values(by=['Breitengrad'])\n",
    "display(duplicateRowsDF)\n",
    "\n",
    "\n",
    "del duplicateRowsDF , dupli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exportieren der Dateien in eine CSV\n",
    "\n",
    "path_csv = \"C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.csv\"\n",
    "df.to_csv(path_csv,\n",
    "            sep = ';',\n",
    "            header = True,\n",
    "            index= True,\n",
    "            decimal= ','\n",
    "            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportieren der Daten in ein Parquet\n",
    "parquet_df= 'C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.zip'\n",
    "df.to_parquet(parquet_df, index = True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "# <a id=3>3. Explorative Datenanalyse </a>\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Importieren der Daten </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_df= 'C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.zip'\n",
    "df = pd.read_parquet(parquet_df)\n",
    "\n",
    "Convert_df= {'Betreiber': 'object', \n",
    "                 'Straße': 'object', \n",
    "                 'Hausnummer': 'object',\n",
    "                 'Adresszusatz' : 'object',\n",
    "                 'Ort' : 'object',\n",
    "                 'Bundesland' : 'object',\n",
    "                 'Kreis/kreisfreie Stadt' : 'object',\n",
    "                 'Breitengrad' : 'float',\n",
    "                 'Längengrad' : 'float',\n",
    "                 'Inbetriebnahmedatum' : 'datetime64',\n",
    "                 'Anschlussleistung' : 'float',\n",
    "                 'Normalladeeinrichtung' : 'object',\n",
    "                 'Anzahl Ladepunkte' : 'int64',\n",
    "                 'Steckertypen1' : 'object',\n",
    "                 'P1 [kW]' : 'float',\n",
    "                 'Public Key1' : 'object',\n",
    "                 'Steckertypen2' : 'object',\n",
    "                 'P2 [kW]' : 'float',\n",
    "                 'Public Key2' : 'object',\n",
    "                 'Steckertypen3' : 'object',\n",
    "                 'P3 [kW]' : 'float',\n",
    "                 'Public Key3' : 'object',\n",
    "                 'Steckertypen4' : 'object',\n",
    "                 'P4 [kW]' : 'float',\n",
    "                 'Public Key4' : 'object'\n",
    "                  }\n",
    "\n",
    "df = df.astype(Convert_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Allgeime Daten über die Datensets </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show missing values in a figure --> Get first Idea how Much Data is missing\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='Greys')\n",
    "plt.xticks(rotation=45, fontsize=6)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('C:/Python/KFW_V1/Ladesaeulenregister_Duplis.pdf')\n",
    "plt.plot()\n",
    "#plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl der Betreiber bei Gruppe \\n ')\n",
    "df_Betreiber_cnt_tmp = df.groupby(['Betreiber'])['Betreiber'].count().sort_values(ascending=False)\n",
    "print(df_Betreiber_cnt_tmp.head(10))\n",
    "print('\\n')\n",
    "\n",
    "print( '# Anzahl der Normalladeeinrichtung \\n')\n",
    "df_n_cnt = df.groupby(['Normalladeeinrichtung'])['Normalladeeinrichtung'].count().sort_values(ascending=False)\n",
    "print(df_n_cnt.head(10))\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Gruppierung nach Anschlussleistung \\n') \n",
    "df_An_cnt = df.groupby(['Anschlussleistung'])['Anschlussleistung'].count().sort_values(ascending=False)\n",
    "print(df_An_cnt.head(10))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Gruppierung nach Bundesland \\n') \n",
    "df_B_cnt = df.groupby(['Bundesland'])['Bundesland'].count().sort_values(ascending=False)\n",
    "print(df_B_cnt.head(10))\n",
    "print('\\n')\n",
    "\n",
    "print('# Gruppierung nach Max Leistung \\n') \n",
    "df_kw_cnt = df.groupby(['P1 [kW]'])['P1 [kW]'].count().sort_values(ascending=False)\n",
    "print(df_kw_cnt.head(10))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl der maximalen Ladepunkten innerhalb von Deutschland \\n') \n",
    "df_lpm_cnt = df['Anzahl Ladepunkte']\n",
    "df_lpm_cnt = df_lpm_cnt.max()\n",
    "print(df_lpm_cnt)\n",
    "print('\\n')\n",
    "\n",
    "# Durchschnittswert\n",
    "print('# Ermittlung der Durchschnittswerte \\n') \n",
    "list_columns = ['Anschlussleistung',\n",
    "                'Anzahl Ladepunkte', 'P1 [kW]', 'P2 [kW]', 'P3 [kW]', 'P4 [kW]']\n",
    "df1 = df[list_columns]\n",
    "print(df1.mean(axis=0, skipna = True))\n",
    "\n",
    "\n",
    "\n",
    "# del df_Betreiber_cnt_tmp ,df_n_cnt ,df_An_cnt ,df_B_cnt ,df_kw_cnt , df_lp_cnt, df_lpm_cnt , df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl von Ladepunkten innerhalb von Deutschland \\n') \n",
    "df_lp_cnt = df['Anzahl Ladepunkte']\n",
    "df_lp_cnt = df_lp_cnt.sum(axis = 0, skipna = True)\n",
    "print(df_lp_cnt)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten einholen\n",
    "#data = df['Inbetriebnahmedatum'].value_counts().sort_index()\n",
    "data = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y').value_counts().sort_index()\n",
    "#df['Inbetriebnahmedatum'] = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y')\n",
    "\n",
    "# Linie erstellen\n",
    "trace = go.Scatter(x = data.index,\n",
    "                   y = data.values,\n",
    "                   marker = dict(color = '#db0000'))\n",
    "# Layout erstellen\n",
    "layout = dict(title = '{} Ladesäulen sortiert nach Inbetriebnahme'.format(df.shape[0]),\n",
    "              xaxis = dict(title = 'Inbetriebnahmejahr'),\n",
    "              yaxis = dict(title = 'Säule'))\n",
    "\n",
    "# Plot erstellen\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)\n",
    "\n",
    "\n",
    "del layout, trace, fig, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellen der Stationen innerhalb Deutschland\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.Längengrad, df.Breitengrad))\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "cities = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n",
    "\n",
    "# We restrict to South America.\n",
    "ax = world[world.name == 'Germany'].plot(\n",
    "    color='white', edgecolor='black')\n",
    "\n",
    "\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "gdf.plot(ax=ax, color='blue',alpha = 0.1 , markersize=3 )\n",
    "\n",
    "## Mathplotly better\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Delete Ladesäulen which are out of Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = ['Anschlussleistung',\n",
    "                'Anzahl Ladepunkte', 'P1 [kW]', 'P2 [kW]', 'P3 [kW]', 'P4 [kW]']\n",
    "df = df[list_columns]\n",
    "corr_matrix = df.corr(method = 'pearson')\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Todos\n",
    "Data Analyses\n",
    "-   Correlation of \"Betreiber\" and \"KW 1\"\n",
    "    -   ONE Hot Encoding\n",
    "-  Some Zooming, missing City and Area \n",
    "\n",
    "\n",
    "\n",
    "Further Ideas\n",
    "- Prediction of future \"Anzahl Ladesäule\"\n",
    "    - Linear Regression\n",
    "    \n",
    "- Establish local data connection to e-car registrations and charging stations, to find out capacity gaps in some regions or not.\n",
    "    -  Which Cities are underpresented\n",
    "- Relate the coordinates of service areas and charging stations to find out if there are gaps.\n",
    "    - Missing Data of Coordinates\n",
    "    - \n",
    "- Distribution of fast charging stations in Germany. Maybe as preliminary work to connect the main traffic routes with it, afterwards.\n",
    "    -  Missing Data \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Inbetriebnahmedatum'] = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y')# Drop all rows with NaN.\n",
    "# df = df.dropna(axis=0)\n",
    "df_null_values = df.isnull().sum()\n",
    "# print('NANs_After_Update?', df_null_values)\n",
    "# print('// complete ........ Pre-Processing')\n",
    "# ------------------------------------------\n",
    "# Exploring the Data\n",
    "# ------------------------------------------\n",
    "# Select only the inserting one\n",
    "list_columns = ['Bundesland','Postleitzahl', 'Breitengrad', 'Längengrad',\n",
    "                'Inbetriebnahmedatum', 'Anschlussleistung',\n",
    "                'Normalladeeinrichtung', 'Anzahl Ladepunkte']\n",
    "df = df[list_columns]\n",
    "# Count column over yeas. Output: Series. Therefore, convert to pandas DataFrame.\n",
    "\n",
    "df_year_count = df['Inbetriebnahmedatum'].dt.year.value_counts().to_frame()\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "sns.barplot(data=df_year_count, x=df_year_count.index, y=\"Inbetriebnahmedatum\", color='gray',\n",
    "             linewidth=1.0)  # , marker='o', label='Portfolio Value', ax=ax[0])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=80)\n",
    "# plt.savefig('fig_count_plot_count_year.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('// complete ....... count plot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "# <a id=4>4. Modellentwicklung </a>\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Extrahieren des Datums und des Monats und der Kalenderwoche </a>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2019-03-19\n",
      "1       2019-10-31\n",
      "2       2019-08-23\n",
      "3       2022-01-05\n",
      "4       2019-02-15\n",
      "           ...    \n",
      "34717   2021-08-31\n",
      "34718   2021-08-31\n",
      "34719   2022-01-01\n",
      "34720   2022-12-09\n",
      "34721   2018-03-22\n",
      "Name: Inbetriebnahmedatum, Length: 34722, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "df = df_raw\n",
    "\n",
    "# Wandle die Spalte \"date\" in ein Datetime-Format um\n",
    "df['Inbetriebnahmedatum'] = pd.to_datetime(df[\"Inbetriebnahmedatum\"])\n",
    "\n",
    "# Extraktion der Kalenderwoche und des Jahres\n",
    "df[\"month\"] = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%m\"))\n",
    "df[\"week\"]  = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%V\"))\n",
    "df[\"year\"]  = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%Y\"))\n",
    "\n",
    "# Erstelle eine neue Spalte \"date_week\" aus dem Datum und der Kalenderwoche\n",
    "df[\"date_week\"] = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%Y-%V\"))\n",
    "df[\"date_month\"] = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"01-%m-%Y\"))\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(df[\"Inbetriebnahmedatum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum= df.groupby('date_week')['Anschlussleistung'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        03\n",
      "1        10\n",
      "2        08\n",
      "3        01\n",
      "4        02\n",
      "         ..\n",
      "34717    08\n",
      "34718    08\n",
      "34719    01\n",
      "34720    12\n",
      "34721    03\n",
      "Name: month, Length: 34722, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('date_week')['Anschlussleistung'].agg(['sum','count']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = df.groupby('date_week')['Anschlussleistung'].agg(['sum','count']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1900-11</th>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-02</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03</th>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01</th>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-51</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-44</th>\n",
       "      <td>7061.00</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-45</th>\n",
       "      <td>3075.95</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-48</th>\n",
       "      <td>2106.20</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-49</th>\n",
       "      <td>4158.95</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-52</th>\n",
       "      <td>13208.90</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum  count\n",
       "date_week                 \n",
       "1900-11       22.00      1\n",
       "1992-02       11.00      1\n",
       "2001-03       22.00      1\n",
       "2007-01       22.00      1\n",
       "2007-51       11.00      1\n",
       "...             ...    ...\n",
       "2022-44     7061.00    105\n",
       "2022-45     3075.95     47\n",
       "2022-48     2106.20     36\n",
       "2022-49     4158.95     92\n",
       "2022-52    13208.90    506\n",
       "\n",
       "[646 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date_week'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[39m=\u001b[39m df_sum[[\u001b[39m'\u001b[39;49m\u001b[39mdate_week\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcount\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[0;32m      2\u001b[0m y \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mZielvariable\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\.virtualenvs\\KFW_V1-n7B7ZO_c\\lib\\site-packages\\pandas\\core\\frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\.virtualenvs\\KFW_V1-n7B7ZO_c\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6113\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6111\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6115\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6117\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\.virtualenvs\\KFW_V1-n7B7ZO_c\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6175\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6176\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date_week'] not in index\""
     ]
    }
   ],
   "source": [
    "X = df_sum[['date_week', 'count']]\n",
    "y = data['Zielvariable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Training data\n",
    "years = [1900, 1950, 2000, 2010, 2020]\n",
    "populations = [1.65, 2.55, 6.14, 6.89, 7.79]\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression().fit(np.array(years).reshape(-1, 1), np.array(populations))\n",
    "\n",
    "# Make predictions for the next 10 years\n",
    "years_future = [2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100]\n",
    "populations_pred = model.predict(np.array(years_future).reshape(-1, 1))\n",
    "\n",
    "# Print the predicted populations\n",
    "for year, population in zip(years_future, populations_pred):\n",
    "    print(f'Predicted population in {year}: {population} billion')\n",
    "\n",
    "print(populations_pred.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(populations_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('KFW_V1-n7B7ZO_c')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a6d2462e65ed54794c76e3a764d49c7eaa874fbe4b0612b96e60aa5b8bc5bc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
