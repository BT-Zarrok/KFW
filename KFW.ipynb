{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladesäulen KFW rc\n",
    "\n",
    "Von  Jannis Breitenstein <br>\n",
    "\n",
    "\n",
    "Diese Notebook ist in folgende Abschnitte unterteilt:\n",
    "z67u.[]\n",
    "+ [1. Import Bibliotheken](#1)<br>\n",
    "+ [2. Laden und Aufbereiten der Zapfsäulendaten](#2)<br>\n",
    "+ [2.1 Laden und Aufbereitung der Daten](#2.1)<br>\n",
    "+ [2.2 Exportieren und Einlesen der Daten](#2.1)<br>\n",
    "+ [3. Explorative Datenanalyse](#3)<br>\n",
    "+ [3.1 Allgeime Daten über die Datensets](#3.1)<br>\n",
    "+ [3.2 Veröffentlichung der Filme](#3.2)<br>\n",
    "+ [3.3 Verteilung der Filmbewertungen](#3.3)<br>\n",
    "+ [3.4 Wann sind die Filme bewertet worden](#3.4)<br>\n",
    "+ [3.5 Verteilung von Filmbewertungen und Benutzern](#3.5)<br>\n",
    "+ [4. Filtern der Daten](#4)<br>\n",
    "+ [5. Anweden des KNN-Modells](#5)<br>\n",
    "+ [5.1 Vorbereitung des KNN-Modells](#5.1)<br>\n",
    "+ [5.2 Berechnung von allen Nachbarn und Export](#5.2)<br>\n",
    "+ [5.3 Vorbereitung für Precision and Recall](#5.3)<br>\n",
    "+ [5.4 Presicion and Recall](#5.4)<br>\n",
    "+ [5.5 Empfehlung mit Hilfe des Fuzzy Algorithmus](#5.5)<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  cd C:\\Python\\KFW_V1\n",
    "##  !{sys.executable} -m pipenv shell\n",
    "## dsad\n",
    "\"\"\"\n",
    "pip3 install virtualenv\n",
    "cd C:\\Python\\KFW_V1\\kfw> \n",
    "python -m venv kfw  --> Zum Erstellen, wenn bereits vorhanden dann Active\n",
    ".\\kfw\\Scripts\\activate\n",
    "--> When Activation is failing: Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy Unrestricted --> Repeat step four\n",
    "--> to run the Jupyter Notebook in virtual Enviroment it is recommended to install all jupyter dependencies --> !{sys.executable} -m pip3 install jupyter\n",
    "\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=1>1. Import Bibliotheken </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "!{sys.executable} --version\n",
    "print(sys.executable)\n",
    "!{sys.executable} -m pip install autokeras\n",
    "!{sys.executable} -m pip install altair\n",
    "!{sys.executable} -m pip install bayesian-optimization\n",
    "!{sys.executable} -m pip install chart_studio\n",
    "!{sys.executable} -m pip install cx_Oracle\n",
    "!{sys.executable} -m pip install dython\n",
    "!{sys.executable} -m pip install fastparquet\n",
    "!{sys.executable} -m pip install fuzzywuzzy\n",
    "!{sys.executable} -m pip install geopandas\n",
    "!{sys.executable} -m pip install graphviz\n",
    "!{sys.executable} -m pip install glom\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "!{sys.executable} -m pip install ipython-sql\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install lime\n",
    "!{sys.executable} -m pip install nltk\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install numpy\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install notebook \n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "# Wichtig\n",
    "!{sys.executable} -m pip install pandas\n",
    "#\n",
    "!{sys.executable} -m pip install pillow\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "!{sys.executable} -m pip install python-Levenshtein\n",
    "!{sys.executable} -m pip install prettytable\n",
    "!{sys.executable} -m pip install pyspark\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install scipy\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install surprise\n",
    "!{sys.executable} -m pip install scikit-surprise \n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install spaCy\n",
    "!{sys.executable} -m pip install sqlalchemy\n",
    "!{sys.executable} -m pip install talos\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install wrangle\n",
    "!{sys.executable} -m pip install requests\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zum Speichern der Daten\n",
    "import pandas as pd\n",
    "\n",
    "# Wird zur Erstellung mehrdimensionalen Arrays benötigt\n",
    "import numpy as np\n",
    "\n",
    "# interaktive Diagramme erstellen\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Lineare Regression \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Datetime\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id=2>2. Laden und Aufbereiten der Daten </a>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Datenaufbereitung </a>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define actual Datapath\n",
    "path = \"C:/Python/KFW_V1/Ladesaeulenregister.csv\"\n",
    "\n",
    "df_raw= pd.read_csv(path,\n",
    "                encoding = \"ISO-8859-1\",\n",
    "                delimiter= ';',\n",
    "                decimal= ',',\n",
    "                skiprows = 10,\n",
    "                engine = 'python')\n",
    "\n",
    "\n",
    "del  path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw\n",
    "\n",
    "## Daten in Float Formatieren\n",
    "\n",
    "df = df[df['Breitengrad'].str.contains('52,19168124567324.') == False]\n",
    "df['Breitengrad'] = df['Breitengrad'].astype(float)\n",
    "\n",
    "#df['Breitengrad'] = df['Breitengrad'].replace('.',',')\n",
    "\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace(',','.') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace(',','.') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace('','') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].str.replace(' ','') \n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace('','0')\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].astype(float)\n",
    "\n",
    "df['P4 [kW]'] = df['P4 [kW]'].replace('.',',')\n",
    "\n",
    "df['Inbetriebnahmedatum'] = pd.to_datetime(df.Inbetriebnahmedatum, dayfirst= True)\n",
    "\n",
    "Convert_df= {'Betreiber': 'object',\n",
    "                 'Straße': 'object', \n",
    "                 'Hausnummer': 'object',\n",
    "                 'Adresszusatz' : 'object',\n",
    "                 'Ort' : 'object',\n",
    "                 'Bundesland' : 'object',\n",
    "                 'Kreis/kreisfreie Stadt' : 'object',\n",
    "                 'Breitengrad' : 'float',\n",
    "                 'Längengrad' : 'float',\n",
    "                 'Inbetriebnahmedatum' : 'datetime64',\n",
    "                 'Anschlussleistung' : 'float',\n",
    "                 'Normalladeeinrichtung' : 'object',\n",
    "                 'Anzahl Ladepunkte' : 'int64',\n",
    "                 'Steckertypen1' : 'object',\n",
    "                 'P1 [kW]' : 'float',\n",
    "                 'Public Key1' : 'object',\n",
    "                 'Steckertypen2' : 'object',\n",
    "                 'P2 [kW]' : 'float',\n",
    "                 'Public Key2' : 'object',\n",
    "                 'Steckertypen3' : 'object',\n",
    "                 'P3 [kW]' : 'float',\n",
    "                 'Public Key3' : 'object',\n",
    "                 'Steckertypen4' : 'object',\n",
    "                 'P4 [kW]' : 'float',\n",
    "                 'Public Key4' : 'object'\n",
    "                  }\n",
    "\n",
    "df = df.astype(Convert_df)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2.2 Allgemeine Informationen zum Datenset </a>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_raw\n",
    "# Ausgabe Datentypen\n",
    "#What are the datatypes in each column?\n",
    "print(df.info())\n",
    "\n",
    "# Let's see what attributes columns we have.\n",
    "print(df.columns)\n",
    "\n",
    "# There are quite some columns. How many, actually?\n",
    "# How many columns do you have?\n",
    "print(len(df.columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wie viele Datensätze haben wir sprich Spalten\n",
    "print(len(df.index))\n",
    "\n",
    "# Was ist die Dimension vom Datenset\n",
    "#What is the dimension of the dataset? Note: Your answer should be a tuple value.\n",
    "print(df.shape)\n",
    "\n",
    "## Wie viele Werte haben die einzelen Spalten\n",
    "print(df.count())\n",
    "\n",
    "## Anzeigen der aktuellen Datenstruktur\n",
    "#display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Löschen von doppelten Spalten\n",
    "df_f = df\n",
    "\n",
    "# Drop all rows with NaN.\n",
    "df_f = df_f.dropna(axis = 0, how = 'all', inplace = False)\n",
    "#df_f = df_f.fillna(\"\", inplace=False)\n",
    "\n",
    "#df_null_values = df_f.isnull().sum()\n",
    "\n",
    "\n",
    "print('Vor dem entfernen hatte der Datensatz {} Zeilen. Nach dem entfernen {}  Insgesamt wurden  entfernt'.format(len(df.index), len(df_f.index) ))\n",
    "\n",
    "del df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Ausgabe der Duplikate\n",
    "dupli = df.duplicated(keep=False).sum()\n",
    "print('In dem Datensatz Ladensauelenregister liegen {} Duplikate vor'.format(dupli))\n",
    "\n",
    "duplicateRowsDF = df[df.duplicated()]\n",
    "duplicateRowsDF = duplicateRowsDF.sort_values(by=['Breitengrad'])\n",
    "display(duplicateRowsDF)\n",
    "\n",
    "\n",
    "del duplicateRowsDF , dupli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exportieren der Dateien in eine CSV\n",
    "\n",
    "path_csv = \"C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.csv\"\n",
    "df.to_csv(path_csv,\n",
    "            sep = ';',\n",
    "            header = True,\n",
    "            index= True,\n",
    "            decimal= ','\n",
    "            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportieren der Daten in ein Parquet\n",
    "parquet_df= 'C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.zip'\n",
    "df.to_parquet(parquet_df, index = True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "# <a id=3>3. Explorative Datenanalyse </a>\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Importieren der Daten </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_df= 'C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.zip'\n",
    "df = pd.read_parquet(parquet_df)\n",
    "\n",
    "Convert_df= {'Betreiber': 'object', \n",
    "                 'Straße': 'object', \n",
    "                 'Hausnummer': 'object',\n",
    "                 'Adresszusatz' : 'object',\n",
    "                 'Ort' : 'object',\n",
    "                 'Bundesland' : 'object',\n",
    "                 'Kreis/kreisfreie Stadt' : 'object',\n",
    "                 'Breitengrad' : 'float',\n",
    "                 'Längengrad' : 'float',\n",
    "                 'Inbetriebnahmedatum' : 'datetime64',\n",
    "                 'Anschlussleistung' : 'float',\n",
    "                 'Normalladeeinrichtung' : 'object',\n",
    "                 'Anzahl Ladepunkte' : 'int64',\n",
    "                 'Steckertypen1' : 'object',\n",
    "                 'P1 [kW]' : 'float',\n",
    "                 'Public Key1' : 'object',\n",
    "                 'Steckertypen2' : 'object',\n",
    "                 'P2 [kW]' : 'float',\n",
    "                 'Public Key2' : 'object',\n",
    "                 'Steckertypen3' : 'object',\n",
    "                 'P3 [kW]' : 'float',\n",
    "                 'Public Key3' : 'object',\n",
    "                 'Steckertypen4' : 'object',\n",
    "                 'P4 [kW]' : 'float',\n",
    "                 'Public Key4' : 'object'\n",
    "                  }\n",
    "\n",
    "df = df.astype(Convert_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Allgeime Daten über die Datensets </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show missing values in a figure --> Get first Idea how Much Data is missing\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='Greys')\n",
    "plt.xticks(rotation=45, fontsize=6)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('C:/Python/KFW_V1/Ladesaeulenregister_Duplis.pdf')\n",
    "plt.plot()\n",
    "#plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl der Betreiber bei Gruppe \\n ')\n",
    "df_Betreiber_cnt_tmp = df.groupby(['Betreiber'])['Betreiber'].count().sort_values(ascending=False)\n",
    "print(df_Betreiber_cnt_tmp.head(10))\n",
    "print('\\n')\n",
    "\n",
    "print( '# Anzahl der Normalladeeinrichtung \\n')\n",
    "df_n_cnt = df.groupby(['Normalladeeinrichtung'])['Normalladeeinrichtung'].count().sort_values(ascending=False)\n",
    "print(df_n_cnt.head(10))\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Gruppierung nach Anschlussleistung \\n') \n",
    "df_An_cnt = df.groupby(['Anschlussleistung'])['Anschlussleistung'].count().sort_values(ascending=False)\n",
    "print(df_An_cnt.head(10))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Gruppierung nach Bundesland \\n') \n",
    "df_B_cnt = df.groupby(['Bundesland'])['Bundesland'].count().sort_values(ascending=False)\n",
    "print(df_B_cnt.head(10))\n",
    "print('\\n')\n",
    "\n",
    "print('# Gruppierung nach Max Leistung \\n') \n",
    "df_kw_cnt = df.groupby(['P1 [kW]'])['P1 [kW]'].count().sort_values(ascending=False)\n",
    "print(df_kw_cnt.head(10))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl der maximalen Ladepunkten innerhalb von Deutschland \\n') \n",
    "df_lpm_cnt = df['Anzahl Ladepunkte']\n",
    "df_lpm_cnt = df_lpm_cnt.max()\n",
    "print(df_lpm_cnt)\n",
    "print('\\n')\n",
    "\n",
    "# Durchschnittswert\n",
    "print('# Ermittlung der Durchschnittswerte \\n') \n",
    "list_columns = ['Anschlussleistung',\n",
    "                'Anzahl Ladepunkte', 'P1 [kW]', 'P2 [kW]', 'P3 [kW]', 'P4 [kW]']\n",
    "df1 = df[list_columns]\n",
    "print(df1.mean(axis=0, skipna = True))\n",
    "\n",
    "\n",
    "\n",
    "# del df_Betreiber_cnt_tmp ,df_n_cnt ,df_An_cnt ,df_B_cnt ,df_kw_cnt , df_lp_cnt, df_lpm_cnt , df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Anzahl von Ladepunkten innerhalb von Deutschland \\n') \n",
    "df_lp_cnt = df['Anzahl Ladepunkte']\n",
    "df_lp_cnt = df_lp_cnt.sum(axis = 0, skipna = True)\n",
    "print(df_lp_cnt)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten einholen\n",
    "#data = df['Inbetriebnahmedatum'].value_counts().sort_index()\n",
    "data = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y').value_counts().sort_index()\n",
    "#df['Inbetriebnahmedatum'] = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y')\n",
    "\n",
    "# Linie erstellen\n",
    "trace = go.Scatter(x = data.index,\n",
    "                   y = data.values,\n",
    "                   marker = dict(color = '#db0000'))\n",
    "# Layout erstellen\n",
    "layout = dict(title = '{} Ladesäulen sortiert nach Inbetriebnahme'.format(df.shape[0]),\n",
    "              xaxis = dict(title = 'Inbetriebnahmejahr'),\n",
    "              yaxis = dict(title = 'Säule'))\n",
    "\n",
    "# Plot erstellen\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)\n",
    "\n",
    "\n",
    "del layout, trace, fig, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellen der Stationen innerhalb Deutschland\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.Längengrad, df.Breitengrad))\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "cities = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n",
    "\n",
    "# We restrict to South America.\n",
    "ax = world[world.name == 'Germany'].plot(\n",
    "    color='white', edgecolor='black')\n",
    "\n",
    "\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "gdf.plot(ax=ax, color='blue',alpha = 0.1 , markersize=3 )\n",
    "\n",
    "## Mathplotly better\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Delete Ladesäulen which are out of Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = ['Anschlussleistung',\n",
    "                'Anzahl Ladepunkte', 'P1 [kW]', 'P2 [kW]', 'P3 [kW]', 'P4 [kW]']\n",
    "df = df[list_columns]\n",
    "corr_matrix = df.corr(method = 'pearson')\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Todos\n",
    "Data Analyses\n",
    "-   Correlation of \"Betreiber\" and \"KW 1\"\n",
    "    -   ONE Hot Encoding\n",
    "-  Some Zooming, missing City and Area \n",
    "\n",
    "\n",
    "\n",
    "Further Ideas\n",
    "- Prediction of future \"Anzahl Ladesäule\"\n",
    "    - Linear Regression\n",
    "    \n",
    "- Establish local data connection to e-car registrations and charging stations, to find out capacity gaps in some regions or not.\n",
    "    -  Which Cities are underpresented\n",
    "- Relate the coordinates of service areas and charging stations to find out if there are gaps.\n",
    "    - Missing Data of Coordinates\n",
    "    - \n",
    "- Distribution of fast charging stations in Germany. Maybe as preliminary work to connect the main traffic routes with it, afterwards.\n",
    "    -  Missing Data \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Inbetriebnahmedatum'] = pd.to_datetime(df['Inbetriebnahmedatum'], format='%d.%m.%Y')# Drop all rows with NaN.\n",
    "# df = df.dropna(axis=0)\n",
    "df_null_values = df.isnull().sum()\n",
    "# print('NANs_After_Update?', df_null_values)\n",
    "# print('// complete ........ Pre-Processing')\n",
    "# ------------------------------------------\n",
    "# Exploring the Data\n",
    "# ------------------------------------------\n",
    "# Select only the inserting one\n",
    "list_columns = ['Bundesland','Postleitzahl', 'Breitengrad', 'Längengrad',\n",
    "                'Inbetriebnahmedatum', 'Anschlussleistung',\n",
    "                'Normalladeeinrichtung', 'Anzahl Ladepunkte']\n",
    "df = df[list_columns]\n",
    "# Count column over yeas. Output: Series. Therefore, convert to pandas DataFrame.\n",
    "\n",
    "df_year_count = df['Inbetriebnahmedatum'].dt.year.value_counts().to_frame()\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "sns.barplot(data=df_year_count, x=df_year_count.index, y=\"Inbetriebnahmedatum\", color='gray',\n",
    "             linewidth=1.0)  # , marker='o', label='Portfolio Value', ax=ax[0])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=80)\n",
    "# plt.savefig('fig_count_plot_count_year.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('// complete ....... count plot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "# <a id=4>4. Modellentwicklung </a>\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Extrahieren des Datums und des Monats und der Kalenderwoche </a>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportieren der Daten in ein Parquet\n",
    "parquet_df= 'C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.zip'\n",
    "df.to_parquet(parquet_df, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# löschen von Df\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der Daten in ein Parquet\n",
    "parquet_df= 'C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.zip'\n",
    "df = pd.read_parquet(parquet_df)\n",
    "Convert_df= {'Betreiber': 'object',\n",
    "                 'Straße': 'object', \n",
    "                 'Hausnummer': 'object',\n",
    "                 'Adresszusatz' : 'object',\n",
    "                 'Ort' : 'object',\n",
    "                 'Bundesland' : 'object',\n",
    "                 'Kreis/kreisfreie Stadt' : 'object',\n",
    "                 'Breitengrad' : 'float',\n",
    "                 'Längengrad' : 'float',\n",
    "                 'Inbetriebnahmedatum' : 'datetime64',\n",
    "                 'Anschlussleistung' : 'float',\n",
    "                 'Normalladeeinrichtung' : 'object',\n",
    "                 'Anzahl Ladepunkte' : 'int64',\n",
    "                 'Steckertypen1' : 'object',\n",
    "                 'P1 [kW]' : 'float',\n",
    "                 'Public Key1' : 'object',\n",
    "                 'Steckertypen2' : 'object',\n",
    "                 'P2 [kW]' : 'float',\n",
    "                 'Public Key2' : 'object',\n",
    "                 'Steckertypen3' : 'object',\n",
    "                 'P3 [kW]' : 'float',\n",
    "                 'Public Key3' : 'object',\n",
    "                 'Steckertypen4' : 'object',\n",
    "                 'P4 [kW]' : 'float',\n",
    "                 'Public Key4' : 'object'\n",
    "                  }\n",
    "\n",
    "df = df.astype(Convert_df)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wandle die Spalte \"date\" in ein Datetime-Format um\n",
    "df[\"Inbetriebnahmedatum\"] = pd.to_datetime(df[\"Inbetriebnahmedatum\"])\n",
    "\n",
    "# Extraktion der Kalenderwoche und des Jahres\n",
    "df[\"month\"] = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%m\"))\n",
    "df[\"week\"]  = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%V\"))\n",
    "df[\"year\"]  = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%Y\"))\n",
    "\n",
    "# Erstelle eine neue Spalte \"date_week\" aus dem Datum und der Kalenderwoche\n",
    "df[\"date_week\"] = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%Y-%V\"))\n",
    "df[\"date_month\"] = df[\"Inbetriebnahmedatum\"].apply(lambda x: x.strftime(\"%Y-%m-01\"))\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(df[\"date_month\"])\n",
    "\n",
    "df['date_month'] = pd.to_datetime(df['date_month'])\n",
    "\n",
    "# Gruppieren nach Monatlichen Daten\n",
    "df_sum = df.groupby('date_month')['Anschlussleistung'].agg(['sum','count']) \n",
    "\n",
    "df_sum = df_sum.reset_index()\n",
    "\n",
    "df_sum_n = df_sum.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168 entries, 0 to 167\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   date_month  168 non-null    datetime64[ns]\n",
      " 1   sum         168 non-null    float64       \n",
      " 2   count       168 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 4.1 KB\n",
      "None\n",
      "-------------------\n",
      "None\n",
      "-------------------\n",
      "  date_month   sum  count\n",
      "0 1900-03-01  22.0      1\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_month</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-03-01</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-10-01</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>37542.00</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>120101.45</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>47888.10</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>33169.65</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>30653.30</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_month        sum  count\n",
       "0   1900-03-01      22.00      1\n",
       "1   1992-10-01      11.00      1\n",
       "2   2001-01-01      22.00      1\n",
       "3   2007-05-01      22.00      1\n",
       "4   2007-12-01      11.00      1\n",
       "..         ...        ...    ...\n",
       "163 2022-05-01   37542.00    574\n",
       "164 2022-06-01  120101.45    930\n",
       "165 2022-07-01   47888.10    723\n",
       "166 2022-08-01   33169.65    567\n",
       "167 2022-09-01   30653.30    619\n",
       "\n",
       "[168 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_sum.info())\n",
    "print(\"-------------------\")\n",
    "print(df_sum.index.name)\n",
    "print(\"-------------------\")\n",
    "print(df_sum.head(1))\n",
    "print(\"-------------------\")\n",
    "display(df_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufgrunddessen, dass die Werte Fehlen füllen wir diese mit 0 \n",
    "new_index = pd.date_range('2010-01-01', '2022-01-01', freq='MS')\n",
    "ts = df_sum.reindex(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exportieren der Dateien in eine CSV\n",
    "\n",
    "path_csv = \"C:/Python/KFW_V1/Ladesaeulenregister_Bearbeitet.xlsx\"\n",
    "df_sum.to_excel(path_csv,\n",
    "            header = True,\n",
    "            index= True\n",
    "        \n",
    "            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_sum[['sum', 'count']]\n",
    "x = df_sum['date_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen Sie ein LinearRegression-Modell\n",
    "model = LinearRegression()\n",
    "\n",
    "# Anpassen Sie das Modell an die Daten\n",
    "model.fit(x, , df['variable2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "# Instanziieren der Regressionsklasse\n",
    "model = LinearRegression()\n",
    "\n",
    "# Trainieren des Modells anhand der gegebenen Daten\n",
    "model.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Daten erstellen\n",
    "time_index = # Ein Zeitindex, z.B. eine Liste von Datumsangaben\n",
    "variable1 = # Eine Liste von Werten für die erste Einflussvariable\n",
    "variable2 = # Eine Liste von Werten für die zweite Einflussvariable\n",
    "\n",
    "# Zeitreihenmodell erstellen\n",
    "model = sm.tsa.statespace.SARIMAX(variable1, variable2, time_index)\n",
    "\n",
    "# Zeitreihenvorhersage durchführen\n",
    "predictions = model.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "# Vorbereiten der Daten in ein Zeitreihenformat\n",
    "# Ihr Code hier\n",
    "\n",
    "# Erstellen und Trainieren des ARIMA-Modells\n",
    "model = sm.tsa.ARIMA(timeseries_data, order=(p, d, q))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Machen von Vorhersagen für zukünftige Zeitpunkte\n",
    "predictions = model_fit.predict(start=future_start_date, end=future_end_date)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Erstellen Sie ein leeres DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Fügen Sie Ihre Daten hinzu. Jede Variable muss über einen Zeitraum aufgezeichnet sein.\n",
    "df['variable1'] = [10, 20, 30, 40, 50]\n",
    "df['variable2'] = [15, 25, 35, 45, 55]\n",
    "df['variable3'] = [20, 30, 40, 50, 60]\n",
    "\n",
    "# Setzen Sie den Index auf den Zeitraum, über den die Daten aufgezeichnet wurden\n",
    "df.index = pd.date_range('2020-01-01', '2020-01-05')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sum[['sum', 'count']]\n",
    "y = df_sum['date_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Training data\n",
    "years = [1900, 1950, 2000, 2010, 2020]\n",
    "populations = [1.65, 2.55, 6.14, 6.89, 7.79]\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression().fit(np.array(years).reshape(-1, 1), np.array(populations))\n",
    "\n",
    "# Make predictions for the next 10 years\n",
    "years_future = [2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100]\n",
    "populations_pred = model.predict(np.array(years_future).reshape(-1, 1))\n",
    "\n",
    "# Print the predicted populations\n",
    "for year, population in zip(years_future, populations_pred):\n",
    "    print(f'Predicted population in {year}: {population} billion')\n",
    "\n",
    "print(populations_pred.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('KFW_V1-n7B7ZO_c')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a6d2462e65ed54794c76e3a764d49c7eaa874fbe4b0612b96e60aa5b8bc5bc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
